Kafka를 어떻게 코인 데이터 스트리밍에 적용할 수 있는지 알아보자 !

## 데이터 흐름 설계 (Kafka 활용)

코인 알람 서비스엔 코인 가격 데이터를 수집하고, 분석 후 알람을 보내는 과정이 필요하다.

카프카를 활용한 데이터 흐름을 간단히 정리해보자.

- 데이터 생산자 (Producer)
    - 코인 시세 API (바이낸스, 업비트, 코인베이스 등)에서 실시간 가격 정보를 가져옴
    - 가격 변동, 거래량, 특정 조건 만족 여부 등을 Kafka 토픽으로 전송
- Kafka 브로커 (Broker)
    - 데이터를 토픽 (예 : `coin-price` 또는 `trade-events`)에 저장
    - 여러 개의 파티션(Partition) 을 사용해 대량 데이터도 빠르게 처리
- 데이터 소비자 (Consumer)
    - 알람 서비스 : 가격이 특정 임계값을 넘으면 사용자에게 알림 전송
    - 저장 서비스 : 데이터를 데이터베이스에 저장하여 나중에 분석
    - 분석 서비스 : 매수/매도 신호 분석 후 특정 조건 만족 시 트레이딩 봇 실행

## Kafka에서 코인 데이터 처리 시 고려할 점

### Topic 설계

코인 데이터는 여러 유형이 있으므로 **적절한 토픽을 나누는 것이 중요**

- `coin-price` → 실시간 가격 정보
- `trade-events` → 거래 이벤트 (거래량 급등, 특정 지표 충족 등)
- `alerts` → 알람 발생 이벤트
- 등등

### 파티션

- 코인 데이터는 초당 수천~수만 개의 업데이트가 발생하므로 파티션을 늘려 병렬 처리하는 것이 필요
- 코인 심볼별로 해서 기반 파티션을 설정할 수도 있음

### Consumer Group 활용

- 알람 서비스, 데이터 저장 서비스, 분석 서비스 등 여러 소비자가 같은 데이터를 활용 가능
- Consumer Group을 설정하면 데이터가 중복 처리되지 않고 균등하게 분배됨

## Kafka + WebSocket을 활용한 실시간 데이터 알림

Kafka는 WebSocket과 함께 사용하면 실시간 알람을 웹이나 모바일로 바로 보낼 수 있다.

- Kafka Consumer → WebSocket 서버 → 사용자에게 실시간 알림

## Kafka + Slack 연동을 활용한 알람 서비스

Kafka Consumer가 특정 조건을 만족하는 이벤트 (`alerts` 토픽)를 감지하면, 이를 Slack Webhook API를 활용하여 Slack 채널로 자동 전송할 수 있다.

- Kafka Consumer → Slack Webhook API → Slack 채널에 메시지 전송
